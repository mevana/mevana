{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This scraper will capture everything except NYT's interactive articles and news wires, which expire.\n",
    "import requests, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from util import get_data_frame \n",
    "import os\n",
    "#os.chdir('/Users/Dell/Desktop')\n",
    "#os.getcwd()\n",
    "import sys\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from time import sleep\n",
    "from time import time\n",
    "from random import randint\n",
    "from warnings import warn\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time2017 = pd.read_csv(r\"C:\\Users\\Dell\\Desktop\\RA work\\2017.csv\")\n",
    "time2018 = pd.read_csv(r\"C:\\Users\\Dell\\Desktop\\RA work\\2017.csv\")\n",
    "time2019 = pd.read_csv(r\"C:\\Users\\Dell\\Desktop\\RA work\\2019.csv\")\n",
    "time2020 = pd.read_csv(r\"C:\\Users\\Dell\\Desktop\\RA work\\2020weeks.csv\")\n",
    "#time2021 = pd.read_csv('2021time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_frame(data,save_file):\n",
    "    df = pd.DataFrame(columns=['delta_time','recent_fb_counts','recent_tw_counts',\n",
    "                              'relatedStories','fb_data','tw_data',\n",
    "                              'li_data','pi_data','predicted_interactions',\n",
    "                              'predicted_timestamp','uuid','publication_timestamp',\n",
    "                              'link','headline','excerpt',\n",
    "                              'keywords','source','image_link',\n",
    "                              'has_video','nw_score','max_nw_score',\n",
    "                              'topics','authors','entities','article'])\n",
    "    for idx in range(len(data['articles'])):\n",
    "        sf = dict(data['articles'][idx])\n",
    "        delta_time = sf['delta_time']\n",
    "        recent_fb_counts = sf['recent_fb_counts']\n",
    "        recent_tw_counts = sf['recent_tw_counts']\n",
    "        #videos = sf['videos'][idx]\n",
    "        relatedStories = sf['relatedStories']\n",
    "        fb_data = sf['fb_data']\n",
    "        tw_data = sf['tw_data']\n",
    "        li_data = sf['li_data']\n",
    "        pi_data = sf['pi_data']\n",
    "        predicted_interactions = sf['predicted_interactions']\n",
    "        predicted_timestamp = sf['predicted_timestamp']\n",
    "        uuid = sf['uuid']\n",
    "        publication_timestamp = sf['publication_timestamp']\n",
    "        link = sf['link']\n",
    "        headline = sf['headline']\n",
    "        excerpt = sf['excerpt']\n",
    "        keywords = sf['keywords']\n",
    "        source = sf['source']\n",
    "        image_link = sf['image_link']\n",
    "        has_video = sf['has_video']\n",
    "        nw_score = sf['nw_score']\n",
    "        max_nw_score = sf['max_nw_score']\n",
    "        topics = sf['topics']\n",
    "        authors = sf['authors']\n",
    "        entities = sf['entities']\n",
    "        #article = \"NA\"\n",
    "        #df.loc[len(df)] = [delta_time,recent_fb_counts,recent_tw_counts,\n",
    "        #                      relatedStories,fb_data,tw_data,\n",
    "        #                      li_data,pi_data,predicted_interactions,\n",
    "        #                      predicted_timestamp,uuid,publication_timestamp,\n",
    "        #                      link,headline,excerpt,\n",
    "        #                      keywords,source,image_link,\n",
    "        #                      has_video,nw_score,max_nw_score,\n",
    "        #                      topics,authors,entities,article]\n",
    "        # downloading article\n",
    "        print('working on url:', link, '; ', str(idx / len(data['articles'])), ' % done')\n",
    "        try:\n",
    "            oo = []\n",
    "            req = rq.get(link).text\n",
    "            soup = bs(req,'html.parser')\n",
    "            abstract = soup.find_all('div',class_='js-subbuzz-wrapper')\n",
    "            #abstract = soup.select('sc-bsh4qr-0 feoWCq uvs-font-a-light sc-1op70jq-4 bsaXCZ,col-sm-12 col-md-10 col-lg-8 _15Q4F,div.main')\n",
    "\n",
    "            for i in abstract:\n",
    "                oo.append(i.get_text())\n",
    "            article = \" \".join(oo)\n",
    "            \n",
    "            df.loc[len(df)] = [delta_time,recent_fb_counts,recent_tw_counts,\n",
    "                              relatedStories,fb_data,tw_data,\n",
    "                              li_data,pi_data,predicted_interactions,\n",
    "                              predicted_timestamp,uuid,publication_timestamp,\n",
    "                              link,headline,excerpt,\n",
    "                              keywords,source,image_link,\n",
    "                              has_video,nw_score,max_nw_score,\n",
    "                              topics,authors,entities,article]  # load into df\n",
    "        except Exception as e:\n",
    "            print(\"E: \" + link)\n",
    "            df.loc[len(df)] = [delta_time,recent_fb_counts,recent_tw_counts,\n",
    "                              relatedStories,fb_data,tw_data,\n",
    "                              li_data,pi_data,predicted_interactions,\n",
    "                              predicted_timestamp,uuid,publication_timestamp,\n",
    "                              link,headline,excerpt,\n",
    "                              keywords,source,image_link,\n",
    "                              has_video,nw_score,max_nw_score,\n",
    "                              topics,authors,entities,e]\n",
    "    df.to_excel(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list = [time2017,time2018,time2019,time2020]\n",
    "names_list = ['2017','2018','2019','2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[    Unnamed: 0        week          start            end\n",
       " 0            1  2017-01-01  1483246800000  1483851599999\n",
       " 1            2  2017-01-08  1483851600000  1484456399999\n",
       " 2            3  2017-01-15  1484456400000  1485061199999\n",
       " 3            4  2017-01-22  1485061200000  1485665999999\n",
       " 4            5  2017-01-29  1485666000000  1486270799999\n",
       " 5            6  2017-02-05  1486270800000  1486875599999\n",
       " 6            7  2017-02-12  1486875600000  1487480399999\n",
       " 7            8  2017-02-19  1487480400000  1488085199999\n",
       " 8            9  2017-02-26  1488085200000  1488689999999\n",
       " 9           10  2017-03-05  1488690000000  1489294799999\n",
       " 10          11  2017-03-12  1489294800000  1489895999999\n",
       " 11          12  2017-03-19  1489896000000  1490500799999\n",
       " 12          13  2017-03-26  1490500800000  1491105599999\n",
       " 13          14  2017-04-02  1491105600000  1491710399999\n",
       " 14          15  2017-04-09  1491710400000  1492315199999\n",
       " 15          16  2017-04-16  1492315200000  1492919999999\n",
       " 16          17  2017-04-23  1492920000000  1493524799999\n",
       " 17          18  2017-04-30  1493524800000  1494129599999\n",
       " 18          19  2017-05-07  1494129600000  1494734399999\n",
       " 19          20  2017-05-14  1494734400000  1495339199999\n",
       " 20          21  2017-05-21  1495339200000  1495943999999\n",
       " 21          22  2017-05-28  1495944000000  1496548799999\n",
       " 22          23  2017-06-04  1496548800000  1497153599999\n",
       " 23          24  2017-06-11  1497153600000  1497758399999\n",
       " 24          25  2017-06-18  1497758400000  1498363199999\n",
       " 25          26  2017-06-25  1498363200000  1498967999999\n",
       " 26          27  2017-07-02  1498968000000  1499572799999\n",
       " 27          28  2017-07-09  1499572800000  1500177599999\n",
       " 28          29  2017-07-16  1500177600000  1500782399999\n",
       " 29          30  2017-07-23  1500782400000  1501387199999\n",
       " 30          31  2017-07-30  1501387200000  1501991999999\n",
       " 31          32  2017-08-06  1501992000000  1502596799999\n",
       " 32          33  2017-08-13  1502596800000  1503201599999\n",
       " 33          34  2017-08-20  1503201600000  1503806399999\n",
       " 34          35  2017-08-27  1503806400000  1504411199999\n",
       " 35          36  2017-09-03  1504411200000  1505015999999\n",
       " 36          37  2017-09-10  1505016000000  1505620799999\n",
       " 37          38  2017-09-17  1505620800000  1506225599999\n",
       " 38          39  2017-09-24  1506225600000  1506830399999\n",
       " 39          40  2017-10-01  1506830400000  1507435199999\n",
       " 40          41  2017-10-08  1507435200000  1508039999999\n",
       " 41          42  2017-10-15  1508040000000  1508644799999\n",
       " 42          43  2017-10-22  1508644800000  1509249599999\n",
       " 43          44  2017-10-29  1509249600000  1509854399999\n",
       " 44          45  2017-11-05  1509854400000  1510462799999\n",
       " 45          46  2017-11-12  1510462800000  1511067599999\n",
       " 46          47  2017-11-19  1511067600000  1511672399999\n",
       " 47          48  2017-11-26  1511672400000  1512277199999\n",
       " 48          49  2017-12-03  1512277200000  1512881999999\n",
       " 49          50  2017-12-10  1512882000000  1513486799999\n",
       " 50          51  2017-12-17  1513486800000  1514091599999\n",
       " 51          52  2017-12-24  1514091600000  1514696399999\n",
       " 52          53  2017-12-31  1514696400000  1515301199999,\n",
       "     Unnamed: 0        week          start            end\n",
       " 0            1  2017-01-01  1483246800000  1483851599999\n",
       " 1            2  2017-01-08  1483851600000  1484456399999\n",
       " 2            3  2017-01-15  1484456400000  1485061199999\n",
       " 3            4  2017-01-22  1485061200000  1485665999999\n",
       " 4            5  2017-01-29  1485666000000  1486270799999\n",
       " 5            6  2017-02-05  1486270800000  1486875599999\n",
       " 6            7  2017-02-12  1486875600000  1487480399999\n",
       " 7            8  2017-02-19  1487480400000  1488085199999\n",
       " 8            9  2017-02-26  1488085200000  1488689999999\n",
       " 9           10  2017-03-05  1488690000000  1489294799999\n",
       " 10          11  2017-03-12  1489294800000  1489895999999\n",
       " 11          12  2017-03-19  1489896000000  1490500799999\n",
       " 12          13  2017-03-26  1490500800000  1491105599999\n",
       " 13          14  2017-04-02  1491105600000  1491710399999\n",
       " 14          15  2017-04-09  1491710400000  1492315199999\n",
       " 15          16  2017-04-16  1492315200000  1492919999999\n",
       " 16          17  2017-04-23  1492920000000  1493524799999\n",
       " 17          18  2017-04-30  1493524800000  1494129599999\n",
       " 18          19  2017-05-07  1494129600000  1494734399999\n",
       " 19          20  2017-05-14  1494734400000  1495339199999\n",
       " 20          21  2017-05-21  1495339200000  1495943999999\n",
       " 21          22  2017-05-28  1495944000000  1496548799999\n",
       " 22          23  2017-06-04  1496548800000  1497153599999\n",
       " 23          24  2017-06-11  1497153600000  1497758399999\n",
       " 24          25  2017-06-18  1497758400000  1498363199999\n",
       " 25          26  2017-06-25  1498363200000  1498967999999\n",
       " 26          27  2017-07-02  1498968000000  1499572799999\n",
       " 27          28  2017-07-09  1499572800000  1500177599999\n",
       " 28          29  2017-07-16  1500177600000  1500782399999\n",
       " 29          30  2017-07-23  1500782400000  1501387199999\n",
       " 30          31  2017-07-30  1501387200000  1501991999999\n",
       " 31          32  2017-08-06  1501992000000  1502596799999\n",
       " 32          33  2017-08-13  1502596800000  1503201599999\n",
       " 33          34  2017-08-20  1503201600000  1503806399999\n",
       " 34          35  2017-08-27  1503806400000  1504411199999\n",
       " 35          36  2017-09-03  1504411200000  1505015999999\n",
       " 36          37  2017-09-10  1505016000000  1505620799999\n",
       " 37          38  2017-09-17  1505620800000  1506225599999\n",
       " 38          39  2017-09-24  1506225600000  1506830399999\n",
       " 39          40  2017-10-01  1506830400000  1507435199999\n",
       " 40          41  2017-10-08  1507435200000  1508039999999\n",
       " 41          42  2017-10-15  1508040000000  1508644799999\n",
       " 42          43  2017-10-22  1508644800000  1509249599999\n",
       " 43          44  2017-10-29  1509249600000  1509854399999\n",
       " 44          45  2017-11-05  1509854400000  1510462799999\n",
       " 45          46  2017-11-12  1510462800000  1511067599999\n",
       " 46          47  2017-11-19  1511067600000  1511672399999\n",
       " 47          48  2017-11-26  1511672400000  1512277199999\n",
       " 48          49  2017-12-03  1512277200000  1512881999999\n",
       " 49          50  2017-12-10  1512882000000  1513486799999\n",
       " 50          51  2017-12-17  1513486800000  1514091599999\n",
       " 51          52  2017-12-24  1514091600000  1514696399999\n",
       " 52          53  2017-12-31  1514696400000  1515301199999,\n",
       "         week         start           end\n",
       " 0     1/1/19  1.546320e+12  1.546920e+12\n",
       " 1     1/8/19  1.546920e+12  1.547530e+12\n",
       " 2    1/15/19  1.547530e+12  1.548130e+12\n",
       " 3    1/22/19  1.548130e+12  1.548740e+12\n",
       " 4    1/29/19  1.548740e+12  1.549340e+12\n",
       " 5     2/5/19  1.549340e+12  1.549950e+12\n",
       " 6    2/12/19  1.549950e+12  1.550550e+12\n",
       " 7    2/19/19  1.550550e+12  1.551160e+12\n",
       " 8    2/26/19  1.551160e+12  1.551760e+12\n",
       " 9     3/5/19  1.551760e+12  1.552360e+12\n",
       " 10   3/12/19  1.552360e+12  1.552970e+12\n",
       " 11   3/19/19  1.552970e+12  1.553570e+12\n",
       " 12   3/26/19  1.553570e+12  1.554180e+12\n",
       " 13    4/2/19  1.554180e+12  1.554780e+12\n",
       " 14    4/9/19  1.554780e+12  1.555390e+12\n",
       " 15   4/16/19  1.555390e+12  1.555990e+12\n",
       " 16   4/23/19  1.555990e+12  1.556600e+12\n",
       " 17   4/30/19  1.556600e+12  1.557200e+12\n",
       " 18    5/7/19  1.557200e+12  1.557810e+12\n",
       " 19   5/14/19  1.557810e+12  1.558410e+12\n",
       " 20   5/21/19  1.558410e+12  1.559020e+12\n",
       " 21   5/28/19  1.559020e+12  1.559620e+12\n",
       " 22    6/4/19  1.559620e+12  1.560230e+12\n",
       " 23   6/11/19  1.560230e+12  1.560830e+12\n",
       " 24   6/18/19  1.560830e+12  1.561440e+12\n",
       " 25   6/25/19  1.561440e+12  1.562040e+12\n",
       " 26    7/2/19  1.562040e+12  1.562640e+12\n",
       " 27    7/9/19  1.562640e+12  1.563250e+12\n",
       " 28   7/16/19  1.563250e+12  1.563850e+12\n",
       " 29   7/23/19  1.563850e+12  1.564460e+12\n",
       " 30   7/30/19  1.564460e+12  1.565060e+12\n",
       " 31    8/6/19  1.565060e+12  1.565670e+12\n",
       " 32   8/13/19  1.565670e+12  1.566270e+12\n",
       " 33   8/20/19  1.566270e+12  1.566880e+12\n",
       " 34   8/27/19  1.566880e+12  1.567480e+12\n",
       " 35    9/3/19  1.567480e+12  1.568090e+12\n",
       " 36   9/10/19  1.568090e+12  1.568690e+12\n",
       " 37   9/17/19  1.568690e+12  1.569300e+12\n",
       " 38   9/24/19  1.569300e+12  1.569900e+12\n",
       " 39   10/1/19  1.569900e+12  1.570510e+12\n",
       " 40   10/8/19  1.570510e+12  1.571110e+12\n",
       " 41  10/15/19  1.571110e+12  1.571720e+12\n",
       " 42  10/22/19  1.571720e+12  1.572320e+12\n",
       " 43  10/29/19  1.572320e+12  1.572930e+12\n",
       " 44   11/5/19  1.572930e+12  1.573530e+12\n",
       " 45  11/12/19  1.573530e+12  1.574140e+12\n",
       " 46  11/19/19  1.574140e+12  1.574740e+12\n",
       " 47  11/26/19  1.574740e+12  1.575350e+12\n",
       " 48   12/3/19  1.575350e+12  1.575950e+12\n",
       " 49  12/10/19  1.575950e+12  1.576560e+12\n",
       " 50  12/17/19  1.576560e+12  1.577160e+12\n",
       " 51  12/24/19  1.577160e+12  1.577770e+12,\n",
       "     Unnamed: 0  week          start            end\n",
       " 0            1     1  1577854800000  1578459599999\n",
       " 1            2     2  1578459600000  1579064399999\n",
       " 2            3     3  1579064400000  1579669199999\n",
       " 3            4     4  1579669200000  1580273999999\n",
       " 4            5     5  1580274000000  1580878799999\n",
       " 5            6     6  1580878800000  1581483599999\n",
       " 6            7     7  1581483600000  1582088399999\n",
       " 7            8     8  1582088400000  1582693199999\n",
       " 8            9     9  1582693200000  1583297999999\n",
       " 9           10    10  1583298000000  1583899199999\n",
       " 10          11    11  1583899200000  1584503999999\n",
       " 11          12    12  1584504000000  1585108799999\n",
       " 12          13    13  1585108800000  1585713599999\n",
       " 13          14    14  1585713600000  1586318399999\n",
       " 14          15    15  1586318400000  1586923199999\n",
       " 15          16    16  1586923200000  1587527999999\n",
       " 16          17    17  1587528000000  1588132799999\n",
       " 17          18    18  1588132800000  1588737599999\n",
       " 18          19    19  1588737600000  1589342399999\n",
       " 19          20    20  1589342400000  1589947199999\n",
       " 20          21    21  1589947200000  1590551999999\n",
       " 21          22    22  1590552000000  1591156799999\n",
       " 22          23    23  1591156800000  1591761599999\n",
       " 23          24    24  1591761600000  1592366399999\n",
       " 24          25    25  1592366400000  1592971199999\n",
       " 25          26    26  1592971200000  1593575999999\n",
       " 26          27    27  1593576000000  1594180799999\n",
       " 27          28    28  1594180800000  1594785599999\n",
       " 28          29    29  1594785600000  1595390399999\n",
       " 29          30    30  1595390400000  1595995199999\n",
       " 30          31    31  1595995200000  1596599999999\n",
       " 31          32    32  1596600000000  1597204799999\n",
       " 32          33    33  1597204800000  1597809599999\n",
       " 33          34    34  1597809600000  1598414399999\n",
       " 34          35    35  1598414400000  1599019199999\n",
       " 35          36    36  1599019200000  1599623999999\n",
       " 36          37    37  1599624000000  1600228799999\n",
       " 37          38    38  1600228800000  1600833599999\n",
       " 38          39    39  1600833600000  1601438399999\n",
       " 39          40    40  1601438400000  1602043199999\n",
       " 40          41    41  1602043200000  1602647999999\n",
       " 41          42    42  1602648000000  1603252799999\n",
       " 42          43    43  1603252800000  1603857599999\n",
       " 43          44    44  1603857600000  1604465999999\n",
       " 44          45    45  1604466000000  1605070799999\n",
       " 45          46    46  1605070800000  1605675599999\n",
       " 46          47    47  1605675600000  1606280399999\n",
       " 47          48    48  1606280400000  1606885199999\n",
       " 48          49    49  1606885200000  1607489999999\n",
       " 49          50    50  1607490000000  1608094799999\n",
       " 50          51    51  1608094800000  1608699599999\n",
       " 51          52    52  1608699600000  1609304399999]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on url: https://www.zerohedge.com/geopolitical/nearly-200-people-arrested-across-australia-deliberately-starting-bushfires ;  0.0  % done\n",
      "working on url: https://www.zerohedge.com/political/why-un-hiring-english-speaking-disarmament-officers-new-york ;  0.1  % done\n",
      "working on url: https://www.zerohedge.com/geopolitical/new-colonization-china-building-enormous-self-sustaining-chinese-cities-all-over ;  0.2  % done\n",
      "working on url: https://www.zerohedge.com/geopolitical/round-two-us-drone-airstrikes-kill-six-pro-iran-militia-commanders ;  0.3  % done\n",
      "working on url: https://www.zerohedge.com/geopolitical/six-b-52-bombers-ordered-indian-ocean-base-be-available-against-iran ;  0.4  % done\n",
      "working on url: https://www.zerohedge.com/political/giuliani-says-ukraine-corruption-came-highest-levels-obama-administration-wants-testify ;  0.5  % done\n",
      "working on url: https://www.zerohedge.com/geopolitical/rocket-attack-shuts-down-baghdad-airport-after-joint-us-iraqi-base-targeted ;  0.6  % done\n",
      "working on url: https://www.zerohedge.com/geopolitical/iran-deploys-f-14-fighter-jets-puts-ballistic-missile-bases-high-alert ;  0.7  % done\n",
      "working on url: https://www.zerohedge.com/geopolitical/christians-beheaded-christmas-west-goes-back-sleep ;  0.8  % done\n",
      "working on url: https://www.zerohedge.com/geopolitical/trump-says-us-will-not-leave-iraq-unless-billions-air-base-are-repaid ;  0.9  % done\n"
     ]
    }
   ],
   "source": [
    "api_key = 'sVHGmwha1G7C7'\n",
    "api_endpoint = 'https://api.newswhip.com/v1/articles?key=%s' % api_key\n",
    "for j in range(3,4):\n",
    "    for i in range(0,1):\n",
    "        s = int(time_list[j]['start'][i])\n",
    "        e = int(time_list[j]['end'][i])\n",
    "        data8 = json.dumps({\"filters\":['domain:zerohedge.com'],'size':10,'find_related': False,'from':s,'to':e,'sort_by':\"fb_tw_and_li\"})\n",
    "        r = requests.post(url = api_endpoint, data = data8)\n",
    "        response = r.text\n",
    "        datastore = json.loads(response)\n",
    "        get_data_frame(datastore,\"C:/Users/Dell/Desktop/RA work_00\" + str(names_list[j]) + \"_week_\" + str(i) + \".xlsx\")\n",
    "        if i == 53:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
